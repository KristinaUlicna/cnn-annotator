{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training for Cell Cycle State Classification\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This notebook allows you to train a convolutional neural network (CNN) using your annotated single-cell image patches & make new predictions about the labels of previously unseen images. Follow the step-wise instructions to proceed with the network training and testing of the accuracy. \n",
    "\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "1. You are using the virtual environment of the [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb \"Google Colaboratory\"). To be able to train the neural network on your annotated data, you must first **import your data** into the folders to source from. Please follow the instructions after executing the first cell of this notebook.\n",
    "\n",
    "2. If using Google Colab: This session will 'timeout' if you do not interact with it. It's 90 minutes if you close the browser or 12 hours if you keep the browser open. Additionally, if you close your browser with a code cell is running, if that same cell has not finished, when you reopen the browser it will still be running (the current executing cell keeps running even after browser is closed). Please visit this [StackOverflow](https://stackoverflow.com/questions/54057011/google-colab-session-timeout \"Google Colab Session Timeout\") discussion for more details.\n",
    "\n",
    "\n",
    "### Running Instructions:\n",
    "\n",
    "1. Prior to running the whole notebook in one go, make sure to execute the first cell containing code. This allows to install the CellX library & create local directories in the environment of the virtual machine. \n",
    "\n",
    "2. The executed first cell will print ```Building wheel for cellx (setup.py) ... done```. Click on the ``` 📁``` folder icon located on the left-side dashboard of the Colab notebook. You should now see 4 subfolders in this directory: \"sample_data\" (default), \"logs\" \"train\" and \"test\" folder, which should all be empty.\n",
    "\n",
    "3. At this point, you should **manually move your 'annotation_XXX.zip' files into the \"train\" and \"test\" folders**. Doing so will allow the image patch data to be processed, divided into categories and used for model training & predictions.\n",
    "\n",
    "4. You can now now run the entire notebook by clicking on ```Runtime``` > ```Run``` in the upper main dashboard. Re-running the initial cell will fail to create the \"logs\" \"train\" and \"test\" folders as those are already in the directory. \n",
    "\n",
    "5. Prior to training of the model, this notebook will distribute the image patch data into the training & testing sets and introduce data augmentations. The notebook will ultimately train the neural network based on the hyperparameters you've set up.\n",
    "\n",
    "6. During training, you can actively visualise what the network is doing via [TensorBoard](https://www.tensorflow.org/tensorboard/get_started \"TensorFlow || Tensorboard\"), a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy training!**\n",
    "\n",
    "*Your [CellX](http://lowe.cs.ucl.ac.uk/cellx.html \"Lowe Lab @ UCL\") team*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the CellX library & create subdirectories in the virtual machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using colab, install cellx library and make log and data folders\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install -q git+git://github.com/quantumjot/cellx.git\n",
    "    !mkdir logs\n",
    "    !mkdir train\n",
    "    !mkdir test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and CellX toolkit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from skimage.transform import resize\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cellx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2b9a6807f962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcellx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcellx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcellx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrite_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcellx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mappend_conditional_augmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation_label_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcellx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboard_confusion_matrix_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cellx'"
     ]
    }
   ],
   "source": [
    "from cellx.layers import Encoder2D\n",
    "from cellx.tools.dataset import build_dataset\n",
    "from cellx.tools.dataset import write_dataset\n",
    "from cellx.augmentation.utils import append_conditional_augmentation, augmentation_label_handler\n",
    "from cellx.callbacks import tensorboard_confusion_matrix_callback\n",
    "from cellx.core import load_model\n",
    "from cellx.tools.confusion import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths & class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./train\"\n",
    "TEST_PATH = \"./test\"\n",
    "TRAIN_FILE = os.path.join(TRAIN_PATH, 'CNN_train.tfrecord')\n",
    "TEST_FILE = os.path.join(TEST_PATH, 'CNN_test.tfrecord')\n",
    "LABELS = [\"Interphase\", \"Prometaphase\", \"Metaphase\", \"Anaphase\", \"Apoptosis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate TensorFlow Record (TFRecord) files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(\n",
    "    root, \n",
    "    filename,\n",
    "    labels=LABELS\n",
    "):\n",
    "    \n",
    "    _images = []\n",
    "    _labels = []\n",
    "    \n",
    "    # find the zip files:\n",
    "    zipfiles = [os.path.join(root, f) for f in os.listdir(root) if f.endswith(\".zip\") and f.startswith(\"annotation_\")]\n",
    "    \n",
    "    if len(zipfiles) == 0:\n",
    "        raise Exception(\"Warning, no 'annotation' zip files found in the directory.\")\n",
    "    \n",
    "    for zfn in zipfiles:\n",
    "        print(f\"Loading file: {zfn}\")\n",
    "        with zipfile.ZipFile(zfn, 'r') as zip_data:\n",
    "            files = zip_data.namelist()\n",
    "\n",
    "            for numeric_label, label in enumerate(labels):\n",
    "\n",
    "                patch_files = [f for f in files if f.endswith(\".tif\") and f.startswith(label.capitalize())]\n",
    "                images = [plt.imread(zip_data.open(f)) for f in patch_files]\n",
    "                images_resized = [resize(img, (64, 64), preserve_range=True) for img in images]\n",
    "\n",
    "                _images += images_resized\n",
    "                _labels += [numeric_label] * len(images_resized)\n",
    "\n",
    "                \n",
    "    images_arr = np.stack(_images, axis=0)[..., np.newaxis]\n",
    "    labels_arr = np.stack(_labels, axis=0)\n",
    "    \n",
    "    print(f\"Total images: {images_arr.shape[0]}\")\n",
    "    write_dataset(filename, images_arr.astype(np.uint8), labels=labels_arr.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: \n",
    "\n",
    "**Prior to calling the function to create the TFRecods files:**\n",
    "\n",
    "You need to manually drag the annotation_XXX.zip files into the newly created folders. If you are working in the Google Colab environment, click on the folder icon at the left-side dashboard, which should now contain the 'logs', 'train' and 'test' directories. They should be empty until you drag your annotation files into them.\n",
    "\n",
    "Once the files have been imported, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2b1426cf0eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_tf_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcreate_tf_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cc2c1cedf209>\u001b[0m in \u001b[0;36mcreate_tf_record\u001b[0;34m(root, filename, labels)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# find the zip files:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mzipfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".zip\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"annotation_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train'"
     ]
    }
   ],
   "source": [
    "create_tf_record(TRAIN_PATH, TRAIN_FILE)\n",
    "create_tf_record(TEST_PATH, TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the \"load_model\" function from the CellX library, we can import models without needing to specify the CellX custom layers that had been used to build them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9f61c5cd0e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'model'\n",
    "model = load_model('{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the test dataset, without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@augmentation_label_handler\n",
    "def normalize(img):\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    # clip to 4 standard deviations\n",
    "    img = tf.clip_by_value(img, -4., 4.)\n",
    "    tf.debugging.check_numerics(img, \"Image contains NaN\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = build_dataset(TEST_FILE, read_label=True)\n",
    "test_dataset = test_dataset.map(normalize)\n",
    "test_dataset = test_dataset.take(-1).as_numpy_iterator()\n",
    "\n",
    "test_images, test_labels = zip(*list(test_dataset))\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model on the Test_Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of test_images should be (N,64,64,1) where N is the number of individual images in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-09e27798bff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape = (N,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_images) # shape = (N,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'softmax' function transforms test_predictions into an array of scores for each class for each instance in the testing set. Across classes, the scores sum to one. The class associated with the highest score is the model's 'prediction'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = softmax(test_predictions,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Testing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample N images out of the testing set to check the model's predictions on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_Testing_Predictions(\n",
    "    image_num_list, # indices of the examples in the testing set to be shown\n",
    "    test_images\n",
    "):\n",
    "    plt.figure(figsize=(10,3*(int(len(image_num_list)/5)+1)))\n",
    "    plt.suptitle('Predictions',fontsize=25,x=0.5,y=0.95)\n",
    "    for image_num in image_num_list:\n",
    "        plt.subplot(int(len(image_num_list)/5)+1,5,np.where(image_num_list==image_num)[0]+1)\n",
    "        plt.imshow(test_images[image_num,:,:,0])\n",
    "        plt.title('Image {}'.format(image_num))\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.xlabel(LABELS[np.argmax(test_predictions[image_num])])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Testing_Predictions(np.arange(21),test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what is a confusion matrix? (explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "test_confusion_matrix = confusion_matrix(test_labels,test_predictions)\n",
    "test_confusion_matrix_plot = plot_confusion_matrix(test_confusion_matrix,LABELS)\n",
    "test_confusion_matrix_plot.show()\n",
    "\n",
    "print('Testing Accuracy = ',accuracy)\n",
    "print('Testing Loss = ',loss)\n",
    "\n",
    "precision,recall,fscore,support = precision_recall_fscore_support(test_labels,test_predictions)\n",
    "print('Testing Precision = ',precision)\n",
    "print('Testing Recall = ',recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
